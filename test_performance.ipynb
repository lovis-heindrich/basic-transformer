{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from src.model import Transformer, TransformerConfig\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/config.json\", \"r\") as f:\n",
    "    settings = json.loads(f.read())\n",
    "\n",
    "with open(\"models/word_data.json\", \"r\") as f:\n",
    "    word_data = json.loads(f.read())\n",
    "\n",
    "word_to_index = {k:int(v) for k, v in word_data[\"word_to_index\"].items()}\n",
    "index_to_word = {int(k):v for k, v in word_data[\"index_to_word\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "config = TransformerConfig(vocab_size=settings[\"vocabulary_size\"], max_input_length=settings[\"max_input_length\"], num_heads=settings[\"num_heads\"], num_blocks=settings[\"num_blocks\"], embedding_size=settings[\"embedding_size\"])\n",
    "transformer = Transformer(config)\n",
    "transformer.load_state_dict(torch.load(\"models/model.pt\", map_location=torch.device(device)))\n",
    "transformer.to(device)\n",
    "transformer.train()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_token(tokens=None, sample=False):\n",
    "    if tokens == None:\n",
    "        tokens = [len(index_to_word)-1]\n",
    "    x = torch.LongTensor([tokens]).to(device)\n",
    "    with torch.no_grad():\n",
    "        y = transformer(x)\n",
    "    # Don't allow the model to generate <unknown> tokens\n",
    "    #y = y[:, :, :y.shape[2]-1]\n",
    "    y = torch.nn.functional.softmax(y[:, -1, :y.shape[2]-1].view(-1).detach().cpu(), dim=0)\n",
    "    if not sample:\n",
    "        pred = y.argmax(dim=-1).view(-1)\n",
    "    else:\n",
    "        dist = torch.distributions.categorical.Categorical(probs=y)\n",
    "        pred = dist.sample([1])\n",
    "    next_word = pred.item()\n",
    "    return next_word\n",
    "\n",
    "def print_sentence(words):\n",
    "    print(\" \".join([index_to_word[word] for word in words]))\n",
    "\n",
    "def generate_sentence(start=None):\n",
    "    if start == None:\n",
    "        sentence = []\n",
    "    else:\n",
    "        words = start.split(\" \")\n",
    "        sentence = [word_to_index[x] for x in words]\n",
    "    \n",
    "    while len(sentence) < settings[\"max_input_length\"]:\n",
    "        next_word = generate_next_token(sentence)\n",
    "        sentence += [next_word]\n",
    "    \n",
    "    print_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if thou didst not hear me speak . hamlet . i am a gentleman . i would not speak with you . horatio . you shall not have me ,\n",
      "you shall not pass me . vernon . i will do you any slight harm . vernon . i humbly thank you . exit . marcellus . i am glad\n",
      "and the painter . sicinius . i thank you , sir . menenius . well , well , be gone . exeunt scene iv . rome . a room seek\n",
      "and i will help thee . exit . scene iii . london . a room in the tower . enter the king , salisbury , northumberland , northumberland , hotspur\n",
      "and , in this great trial , let me be proclaimd . let me be bold , for i am so fearful that i have sick , and think no\n",
      "i have a quarter of the world . falstaff . i would i had been a garter . prince . thou wilt , jack , thou wilt have my visor\n",
      "i warrant you , sir , that you shall be out of a more virtuous than a great and so wise . i have seen you in person of the\n",
      "i will not talk of a song . rosalind . what , ist ? rosalind . marry , heres a husband . rosalind . why , sir , i pray\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(\"if thou didst\")\n",
    "generate_sentence(\"you shall not pass\")\n",
    "generate_sentence(\"and\")\n",
    "generate_sentence(\"and\")\n",
    "generate_sentence(\"and\")\n",
    "generate_sentence(\"i\")\n",
    "generate_sentence(\"i\")\n",
    "generate_sentence(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
