{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from src.model import Transformer, TransformerConfig\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"run_data\"#\"models\"\n",
    "\n",
    "with open(model_folder+\"/config.json\", \"r\") as f:\n",
    "    settings = json.loads(f.read())\n",
    "\n",
    "with open(model_folder+\"/word_data.json\", \"r\") as f:\n",
    "    word_data = json.loads(f.read())\n",
    "\n",
    "word_to_index = {k:int(v) for k, v in word_data[\"word_to_index\"].items()}\n",
    "index_to_word = {int(k):v for k, v in word_data[\"index_to_word\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import seaborn as sns\n",
    "\n",
    "# initial_lr = 0.001\n",
    "# max_lr = 0.004\n",
    "# min_lr = 0.0001\n",
    "# optimizer = torch.optim.Adam([torch.Tensor([[1, 2]]), torch.Tensor([[1]])], lr=initial_lr)\n",
    "\n",
    "# total_epochs = 200\n",
    "# warmup_steps = 40\n",
    "# scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=initial_lr/max_lr, total_iters=warmup_steps)\n",
    "# scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = total_epochs-warmup_steps, eta_min = min_lr)\n",
    "# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[warmup_steps])\n",
    "\n",
    "# lrs = []\n",
    "# for i in range(total_epochs):\n",
    "#     lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "#     lrs.append(lr)\n",
    "#     scheduler.step()\n",
    "\n",
    "# sns.lineplot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "config = TransformerConfig(vocab_size=settings[\"vocabulary_size\"], max_input_length=settings[\"max_input_length\"], num_heads=settings[\"num_heads\"], num_blocks=settings[\"num_blocks\"], embedding_size=settings[\"embedding_size\"])\n",
    "transformer = Transformer(config)\n",
    "transformer.load_state_dict(torch.load(model_folder+\"/model.pt\", map_location=torch.device(device)))\n",
    "transformer.to(device)\n",
    "transformer.train()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_token(tokens=None, sample=False):\n",
    "    if tokens == None:\n",
    "        tokens = [len(index_to_word)-1]\n",
    "    x = torch.LongTensor([tokens]).to(device)\n",
    "    with torch.no_grad():\n",
    "        y = transformer(x)\n",
    "    # Don't allow the model to generate <unknown> tokens\n",
    "    y = torch.nn.functional.softmax(y[:, -1, :y.shape[2]-1].view(-1).detach().cpu(), dim=0)\n",
    "    if not sample:\n",
    "        pred = y.argmax(dim=-1).view(-1)\n",
    "    else:\n",
    "        dist = torch.distributions.categorical.Categorical(probs=y)\n",
    "        pred = dist.sample([1])\n",
    "    next_word = pred.item()\n",
    "    return next_word\n",
    "\n",
    "def print_sentence(words):\n",
    "    print(\" \".join([index_to_word[word] for word in words]))\n",
    "\n",
    "def generate_sentence(start=None, sample=False, length=50):\n",
    "    if start == None:\n",
    "        sentence = []\n",
    "    else:\n",
    "        words = start.split(\" \")\n",
    "        sentence = [word_to_index[x] for x in words]\n",
    "    \n",
    "    while len(sentence)<length:\n",
    "        if len(sentence) < settings[\"max_input_length\"]:\n",
    "            next_word = generate_next_token(sentence, sample)\n",
    "            sentence += [next_word]\n",
    "        else:\n",
    "            next_word = generate_next_token(sentence[-settings[\"max_input_length\"]:], sample)\n",
    "            sentence += [next_word]\n",
    "    \n",
    "    print_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the man ? servant . i am a gentleman . lafew . a gentleman , sir , a gentleman , a gentleman , a gentleman . clown . a gentleman , a knave , a gentleman , a gentleman . clown . a clown . clown . sir\n",
      "what is your purpose ? first lord . i hope , my lord , i cannot tell you . cerimon . i am not , my lord , i am a gentleman of the forest , and i have a daughter to her , and i am a gentleman of\n",
      "what is to me ? i am not able to be a fool , but i will not be a fool . i am a fool , and i will not be sworn to be a woman , and then ill be a woman . i will be sworn to\n",
      "what is he ? second citizen . he is not a man , my lord . third citizen . he has a man , and a man of half a man . third citizen . he has a man , and he is a fool , and a man ,\n",
      "what is he ? first citizen . he is a man of late , and he is not mad . second citizen . he is not hurt , sir , but hes a man . third citizen . hes a man , sir , i pray you , to be\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "for i in range(5):\n",
    "    generate_sentence(\"what is\", False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am a gentleman of love , and a man of all the world . i am a gentleman of a child , and a tall gentleman . sir toby . a fellow , a woman , a woman , a woman , a woman , a woman , a\n",
      "i am a gentleman , and a gentleman of a gentleman . sir toby . sir andrew , i have a letter to you . sir toby . i will be hangd to her , and i will not be sworn straight . sir toby . i will have it\n",
      "i am a villain , and a villain , and a knave , a knave , a fool , a fool , a fool , a fool , a fool , a fool , a very knave . clown . a plague ! a fool , i faith , sir\n",
      "i am a fool , and a soldier . parolles . i am a fool , sir , a man . lafew . i am a devil , sir , a devil , a horse , a rogue , a fool , a very melancholy , a woman , a\n",
      "i am not mad . i am sorry to be sure of that i am not . i am sure you have no true . i am glad of it . i am sorry to have it . i am not of the duke , sir , but i am\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "for i in range(5):\n",
    "    generate_sentence(\"i\", False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the king . king henry . what , art thou dead ? king henry . ay , but what ? clarence . i am , my lord , and i am a king . king henry . i am sorry that i am , i have no subjects in\n",
      "and the wind , the wind , the wind , the wind , the wind , the wind , the wind , the moon , the moon , the moon , the moon , the moon , the moon , the moon , the sky , the moon ; the\n",
      "and the man that is the man . he is a man . i am sure he is a man , and he is a man of all , and i will be sure he is a man . if i be not , i will be sworn to be\n",
      "and the rest . exeunt . scene iv . the same . enter the two or fourth lord scales . the king is dead . first lord . aside . i have been so much . second lord . aside . i am glad of him . i am not\n",
      "and so i do . exit . scene ii . the same . enter a banquet . first citizen . well , sir , i will . fourth citizen . you are welcome , sir ; you shall have the cause . second citizen . you are the people .\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "for i in range(5):\n",
    "    generate_sentence(\"and\", False, 50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples\n",
    "\n",
    "- [if thou didst] not , thou art a fool . i am a fool , and thou art a fool . thou art a fool . clown . i am\n",
    "- [i] have a woman , and i have a good heart . but i will be a man of mine , and i will not be satisfied .\n",
    "- [i] am a man , and i am sure of it . i have said , and i will not be sworn to thee . i am a king ,\n",
    "- [you are] a merciful old wench . i am not able to wait upon my friend . i am glad to have merry a launcelet , if i had a\n",
    "- [you are] a beauteous blossom , and i will encounter thee with my nan . i am a proper friend . anne . i would not play a fool ,\n",
    "- i am not drunk for certain , nor i am not of any part of my sex . i am sorry for neither\n",
    "- [you are] in the field . enter a messenger . messenger . news , madam , news ! cleopatra . what news ? messenger . the news ? messenger . the king is gone . messenger . the lord mortimer is coming . antony . the noble antony is come\n",
    "- [like the sky] , and the wind and the moon . o , what a one that is in the other ?\n",
    "- [i] am a gentleman of love , and a man of all the world ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
