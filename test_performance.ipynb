{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from src.model import Transformer, TransformerConfig\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"run_data\"#\"models\"\n",
    "\n",
    "with open(model_folder+\"/config.json\", \"r\") as f:\n",
    "    settings = json.loads(f.read())\n",
    "\n",
    "with open(model_folder+\"/word_data.json\", \"r\") as f:\n",
    "    word_data = json.loads(f.read())\n",
    "\n",
    "word_to_index = {k:int(v) for k, v in word_data[\"word_to_index\"].items()}\n",
    "index_to_word = {int(k):v for k, v in word_data[\"index_to_word\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import seaborn as sns\n",
    "\n",
    "# initial_lr = 0.001\n",
    "# max_lr = 0.004\n",
    "# min_lr = 0.0001\n",
    "# optimizer = torch.optim.Adam([torch.Tensor([[1, 2]]), torch.Tensor([[1]])], lr=initial_lr)\n",
    "\n",
    "# total_epochs = 200\n",
    "# warmup_steps = 40\n",
    "# scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=initial_lr/max_lr, total_iters=warmup_steps)\n",
    "# scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = total_epochs-warmup_steps, eta_min = min_lr)\n",
    "# scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[warmup_steps])\n",
    "\n",
    "# lrs = []\n",
    "# for i in range(total_epochs):\n",
    "#     lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "#     lrs.append(lr)\n",
    "#     scheduler.step()\n",
    "\n",
    "# sns.lineplot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "config = TransformerConfig(vocab_size=settings[\"vocabulary_size\"], max_input_length=settings[\"max_input_length\"], num_heads=settings[\"num_heads\"], num_blocks=settings[\"num_blocks\"], embedding_size=settings[\"embedding_size\"])\n",
    "transformer = Transformer(config)\n",
    "transformer.load_state_dict(torch.load(model_folder+\"/model.pt\", map_location=torch.device(device)))\n",
    "transformer.to(device)\n",
    "transformer.train()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_token(tokens=None, sample=False):\n",
    "    if tokens == None:\n",
    "        tokens = [len(index_to_word)-1]\n",
    "    x = torch.LongTensor([tokens]).to(device)\n",
    "    with torch.no_grad():\n",
    "        y = transformer(x)\n",
    "    # Don't allow the model to generate <unknown> tokens\n",
    "    y = torch.nn.functional.softmax(y[:, -1, :y.shape[2]-1].view(-1).detach().cpu(), dim=0)\n",
    "    if not sample:\n",
    "        pred = y.argmax(dim=-1).view(-1)\n",
    "    else:\n",
    "        dist = torch.distributions.categorical.Categorical(probs=y)\n",
    "        pred = dist.sample([1])\n",
    "    next_word = pred.item()\n",
    "    return next_word\n",
    "\n",
    "def print_sentence(words):\n",
    "    print(\" \".join([index_to_word[word] for word in words]))\n",
    "\n",
    "def generate_sentence(start=None, sample=False, length=50):\n",
    "    if start == None:\n",
    "        sentence = []\n",
    "    else:\n",
    "        words = start.split(\" \")\n",
    "        sentence = [word_to_index[x] for x in words]\n",
    "    \n",
    "    while len(sentence)<length:\n",
    "        if len(sentence) < settings[\"max_input_length\"]:\n",
    "            next_word = generate_next_token(sentence, sample)\n",
    "            sentence += [next_word]\n",
    "        else:\n",
    "            next_word = generate_next_token(sentence[-settings[\"max_input_length\"]:], sample)\n",
    "            sentence += [next_word]\n",
    "    \n",
    "    print_sentence(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red like the sun , and not a place , but that the very tongue of a man , that he may be a fool . i am a fool , and a man , and a man , a very honest , a very gallant one , and a\n",
      "red like the sun , and make a full of the sun , the moon , the sun , the sky , and the moon , the moon , the sun , the sky , the moon , the moon , the sky , the moon , the moon ,\n",
      "red like the sun , and the wind will not be my flesh . i am a man , and i will not be a man . exit . scene iv . a room in capulets house . enter benvolio , pyramus and thisbe . thisbe . i have met\n",
      "red like the sun , and in the night the sun , and the sun , to be the sun , the sun , the moon , the moon , the moon , the moon , the sun , and the moon , the moon , the sky , the\n",
      "red like the sun , and with a little wind , and then the wind is the sun , the moon , the moon , the wind , the moon , the wind , the moon , the moon , the moon , the moon , the moon , the\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "for i in range(5):\n",
    "    generate_sentence(\"red like the sun\", False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine , and i , and my love , and my love , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my\n",
      "mine own . i will not be merry , for i am sure i have a wife , and i will not be glad to see a man . i am glad i am a gentleman , and i will be sworn to the king . i am a king\n",
      "mine , and my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart , my heart\n",
      "mine honour . i will not trust you . i will be your servant . exit . king . i am sorry i am glad you have a woman . rosaline . i am a poor and a man , and i am a gentleman of a gentleman , and\n",
      "mine own . i am not mad ; i am not mad . i am not mad . i am a gentleman of all the world , and i am sure i am a gentleman , and i am sure i am not i am a gentleman of the king\n"
     ]
    }
   ],
   "source": [
    "transformer.train()\n",
    "for i in range(5):\n",
    "    generate_sentence(\"mine\", False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hark , what noise is this ? enter a messenger . messenger . the queen is gone . messenger . my lord , i have sent for you . the news is gone from rome . messenger . the queen is coming . cleopatra . i have heard the lady\n",
      "through yonder , and in the world , i will not break the fire . exit . scene iii . the same . a room in the palace . enter king , fluellen , fluellen , lords and captain bishop . king . i am glad of the king .\n",
      "through yonder , and then he is , and i am sure he is not . i am sure , he is not here . if he be sure , and yet i will not be satisfied . if he be not , ill be sworn . if he be\n",
      "through yonder field , and in the world , i will not be bold to be a man . but , good night , good night , and i will not be a messenger , for my sake , i am glad to see a man . i am glad\n",
      "may be a little better than a man . i am a gentleman , and i will be sworn to be a soldier , and i will be rid of a man . i will be glad to be a gentleman of the world . exeunt . scene iii .\n",
      "may be well , and so may i . exit . scene ii . the same . a room in the castle . enter king , queen , suffolk , suffolk , northumberland and warwick . king henry . what means this ? queen margaret . o , my good\n",
      "may be a woman . i will not be satisfied . exeunt . scene iv . the park . enter armado , pyramus , pyramus and moonshine . thisbe . you , pyramus , thisbe , do not , though you have the wind - play . pyramus . i\n",
      "and the world of this king , and i will be there . exeunt . scene ii . another part of the field . enter romeo . capulet and nurse . juliet . i am sorry to see her . romeo . o , she is dead . romeo .\n",
      "and the duke of york , the earl of cambridge . king henry . i am , and will be king . king henry . and i , and that i may , my lord . king edward . then , do , and leave thy soul . exeunt .\n",
      "and the world that i have done , and will not be a good thing . i will not be revenged upon my side , nor any of my masters , nor i will not be satisfied . exit . scene iv . the same . enter the guard .\n",
      "i am a gentleman . i am sorry , sir , i am glad you have a man , and have no more ado to have a man to say that i am a man . i am a gentleman , sir , and i am a gentleman of the\n",
      "i am not mad , but yet i am sure , i am not in my house . i am a fool , and i will be a fool . i am a fool , a fool , a fool , a cat , a cat , a fool ,\n",
      "i am sure , and i am a gentleman . i am sorry to be a fool , i am a gentleman , and to be a gentleman . i have sworn to be a fool , and i will be a gentleman . i will not be sworn to\n"
     ]
    }
   ],
   "source": [
    "generate_sentence(\"hark\")\n",
    "generate_sentence(\"through yonder\")\n",
    "generate_sentence(\"through yonder\")\n",
    "generate_sentence(\"through yonder\")\n",
    "generate_sentence(\"may\")\n",
    "generate_sentence(\"may\")\n",
    "generate_sentence(\"may\")\n",
    "generate_sentence(\"and\")\n",
    "generate_sentence(\"and\")\n",
    "generate_sentence(\"and\")\n",
    "generate_sentence(\"i\")\n",
    "generate_sentence(\"i\")\n",
    "generate_sentence(\"i\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best of:\n",
    "\n",
    "- [if thou didst] not , thou art a fool . i am a fool , and thou art a fool . thou art a fool . clown . i am\n",
    "- [i] have a woman , and i have a good heart . but i will be a man of mine , and i will not be satisfied .\n",
    "- [i] am a man , and i am sure of it . i have said , and i will not be sworn to thee . i am a king ,\n",
    "- [you are] a merciful old wench . i am not able to wait upon my friend . i am glad to have merry a launcelet , if i had a\n",
    "- [you are] a beauteous blossom , and i will encounter thee with my nan . i am a proper friend . anne . i would not play a fool ,\n",
    "- i am not drunk for certain , nor i am not of any part of my sex . i am sorry for neither\n",
    "- [you are] in the field . enter a messenger . messenger . news , madam , news ! cleopatra . what news ? messenger . the news ? messenger . the king is gone . messenger . the lord mortimer is coming . antony . the noble antony is come\n",
    "- [like the sky] , and the wind and the moon . o , what a one that is in the other ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
