# basic-transformer
 
## Used resources
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [GPT-2 Architecture graphic](https://en.wikipedia.org/wiki/GPT-2#/media/File:Full_GPT_architecture.png)
- [Jacob Hilton's Deep Learning Curriculum](https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md)
- [Natural Language Processing with Transformers book](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/) (I didn't look at the code samples while creating this implementation but I've read through the given implementation before)